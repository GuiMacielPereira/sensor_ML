{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b21716ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peratouch.data import Data, load_data\n",
    "from peratouch.trainer import Trainer \n",
    "from peratouch.results import Results \n",
    "from peratouch.networks import CNN\n",
    "from peratouch.config import path_five_users_main, path_five_users_first\n",
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "def run_n_users(X, y, n_folds=5):\n",
    "    \"\"\"\n",
    "    Runs entire routine of fitting CNN model to dataset (X, y)self.\n",
    "    Performs Cross-Validation of n_folds on input dataset.\n",
    "    Assumes data is already shuffled.\n",
    "    \"\"\"\n",
    "\n",
    "    D = Data(X, y)\n",
    "\n",
    "    n_out = len(np.unique(y))\n",
    "\n",
    "    # Create indices of several folds\n",
    "    D.make_folds(n_folds)     # Makes indices available inside class\n",
    "\n",
    "    predictions = []\n",
    "    actual_vals = []\n",
    "\n",
    "    # for _ in range(n_folds):     # Run all folds \n",
    "    for _ in range(1):     # Run all folds\n",
    "        D.next_fold()\n",
    "        D.normalize()\n",
    "        D.tensors_to_device()\n",
    "        D.print_shapes()\n",
    "        # D.plot_data()\n",
    "        model = CNN(n_ch=1, out_size=n_out)      # Initialize new model each fold\n",
    "        T = Trainer(D)\n",
    "        T.setup(model, max_epochs=20, batch_size=int(len(D.xtr)/20))       # 20 minibatches\n",
    "        T.train_model(model)\n",
    "        # T.plot_train()\n",
    "        R = Results(D, model)\n",
    "        R.test_metrics()\n",
    "        preds, actual = R.get_preds_actual()\n",
    "\n",
    "        predictions.extend(preds)\n",
    "        actual_vals.extend(actual)\n",
    "\n",
    "    print(sklearn.metrics.classification_report(actual_vals, predictions))\n",
    "    return actual_vals, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70bb0469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Running combination of users  (0, 1, 2)\n",
      "\n",
      "\n",
      "-- New Fold --\n",
      "Train, test and validation arrays normalized to:\n",
      "[1.], [1.0024], [0.9983]\n",
      "Using Device:  cpu , dtype:  torch.float32\n",
      "\n",
      "Raw data shape:  (66079, 1, 32) \n",
      "Labels shape:  (66079,) \n",
      "Shape of test set: (13216, 1, 32) \n",
      "Shape of train set: (44933, 1, 32) \n",
      "Shape of validation set: (7930, 1, 32) \n",
      "Unique labels:  [0 1 2] \n",
      "Fraction of test labels:  [0.36, 0.3, 0.34] \n",
      "Fraction of validation labels:  [0.37, 0.29, 0.34] \n",
      "Fraction of train labels:  [0.37, 0.3, 0.34] \n",
      "dtype of inputs:  torch.float32\n",
      "\n",
      " Start of training model:\n",
      "\n",
      "End of epoch 1: loss_tr=0.595, loss_val=0.616, train=77.1%, val=76.1%\n",
      "End of epoch 3: loss_tr=0.532, loss_val=0.550, train=79.0%, val=78.0%\n",
      "End of epoch 5: loss_tr=0.477, loss_val=0.495, train=81.7%, val=81.1%\n",
      "End of epoch 7: loss_tr=0.487, loss_val=0.507, train=80.4%, val=79.9%\n",
      "End of epoch 9: loss_tr=0.539, loss_val=0.557, train=77.0%, val=75.9%\n",
      "End of epoch 11: loss_tr=0.472, loss_val=0.488, train=81.0%, val=80.3%\n",
      "End of epoch 13: loss_tr=0.457, loss_val=0.478, train=81.9%, val=80.6%\n",
      "End of epoch 15: loss_tr=0.482, loss_val=0.507, train=80.6%, val=79.5%\n",
      "End of epoch 17: loss_tr=0.457, loss_val=0.475, train=81.9%, val=81.2%\n",
      "End of epoch 19: loss_tr=0.423, loss_val=0.442, train=83.6%, val=82.5%\n",
      "\n",
      "Training Complete!\n",
      "Loading best weights for lowest validation loss=0.442 ...\n",
      "\n",
      "Average running time per epoch: 0.71 seconds\n",
      "Total running time: 13.54 seconds\n",
      "\n",
      "Test dataset metrics:\n",
      "Overall Accuracy = 82.6%, Matthews Corr Coef = 0.74\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.83      4703\n",
      "           1       0.87      0.85      0.86      4015\n",
      "           2       0.85      0.72      0.78      4498\n",
      "\n",
      "    accuracy                           0.83     13216\n",
      "   macro avg       0.83      0.83      0.83     13216\n",
      "weighted avg       0.83      0.83      0.82     13216\n",
      "\n",
      "\n",
      "\n",
      "Running combination of users  (0, 1, 3)\n",
      "\n",
      "\n",
      "-- New Fold --\n",
      "Train, test and validation arrays normalized to:\n",
      "[1.], [1.0009], [0.9997]\n",
      "Using Device:  cpu , dtype:  torch.float32\n",
      "\n",
      "Raw data shape:  (66203, 1, 32) \n",
      "Labels shape:  (66203,) \n",
      "Shape of test set: (13241, 1, 32) \n",
      "Shape of train set: (45017, 1, 32) \n",
      "Shape of validation set: (7945, 1, 32) \n",
      "Unique labels:  [0 1 2] \n",
      "Fraction of test labels:  [0.36, 0.3, 0.34] \n",
      "Fraction of validation labels:  [0.37, 0.29, 0.34] \n",
      "Fraction of train labels:  [0.36, 0.3, 0.34] \n",
      "dtype of inputs:  torch.float32\n",
      "\n",
      " Start of training model:\n",
      "\n",
      "End of epoch 1: loss_tr=0.592, loss_val=0.610, train=76.4%, val=75.6%\n",
      "End of epoch 3: loss_tr=0.499, loss_val=0.519, train=80.9%, val=80.0%\n",
      "End of epoch 5: loss_tr=0.502, loss_val=0.518, train=80.9%, val=80.4%\n",
      "End of epoch 7: loss_tr=0.487, loss_val=0.512, train=80.4%, val=78.9%\n",
      "End of epoch 9: loss_tr=0.489, loss_val=0.507, train=80.4%, val=79.4%\n",
      "End of epoch 11: loss_tr=0.450, loss_val=0.468, train=82.5%, val=81.6%\n",
      "End of epoch 13: loss_tr=0.455, loss_val=0.476, train=82.0%, val=81.1%\n",
      "End of epoch 15: loss_tr=0.482, loss_val=0.492, train=80.7%, val=80.2%\n",
      "End of epoch 17: loss_tr=0.445, loss_val=0.460, train=82.7%, val=82.1%\n",
      "End of epoch 19: loss_tr=0.440, loss_val=0.452, train=83.0%, val=82.6%\n",
      "\n",
      "Training Complete!\n",
      "Loading best weights for lowest validation loss=0.450 ...\n",
      "\n",
      "Average running time per epoch: 0.76 seconds\n",
      "Total running time: 14.43 seconds\n",
      "\n",
      "Test dataset metrics:\n",
      "Overall Accuracy = 82.7%, Matthews Corr Coef = 0.74\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      4722\n",
      "           1       0.84      0.76      0.80      3963\n",
      "           2       0.79      0.80      0.80      4556\n",
      "\n",
      "    accuracy                           0.83     13241\n",
      "   macro avg       0.83      0.82      0.82     13241\n",
      "weighted avg       0.83      0.83      0.83     13241\n",
      "\n",
      "\n",
      "\n",
      "Running combination of users  (0, 1, 4)\n",
      "\n",
      "\n",
      "-- New Fold --\n",
      "Train, test and validation arrays normalized to:\n",
      "[1.], [1.0021], [0.9978]\n",
      "Using Device:  cpu , dtype:  torch.float32\n",
      "\n",
      "Raw data shape:  (61673, 1, 32) \n",
      "Labels shape:  (61673,) \n",
      "Shape of test set: (12335, 1, 32) \n",
      "Shape of train set: (41937, 1, 32) \n",
      "Shape of validation set: (7401, 1, 32) \n",
      "Unique labels:  [0 1 2] \n",
      "Fraction of test labels:  [0.39, 0.32, 0.29] \n",
      "Fraction of validation labels:  [0.39, 0.31, 0.29] \n",
      "Fraction of train labels:  [0.39, 0.32, 0.29] \n",
      "dtype of inputs:  torch.float32\n",
      "\n",
      " Start of training model:\n",
      "\n",
      "End of epoch 1: loss_tr=0.651, loss_val=0.668, train=72.7%, val=72.6%\n",
      "End of epoch 3: loss_tr=0.531, loss_val=0.556, train=76.2%, val=75.2%\n",
      "End of epoch 5: loss_tr=0.518, loss_val=0.545, train=77.4%, val=76.3%\n",
      "End of epoch 7: loss_tr=0.592, loss_val=0.615, train=73.4%, val=71.8%\n",
      "End of epoch 9: loss_tr=0.496, loss_val=0.521, train=78.2%, val=77.0%\n",
      "End of epoch 11: loss_tr=0.464, loss_val=0.486, train=79.7%, val=78.2%\n",
      "End of epoch 13: loss_tr=0.468, loss_val=0.486, train=79.5%, val=78.9%\n",
      "End of epoch 15: loss_tr=0.470, loss_val=0.490, train=79.6%, val=78.6%\n",
      "End of epoch 17: loss_tr=0.471, loss_val=0.498, train=79.1%, val=77.7%\n",
      "End of epoch 19: loss_tr=0.453, loss_val=0.475, train=80.2%, val=79.1%\n",
      "\n",
      "Training Complete!\n",
      "Loading best weights for lowest validation loss=0.470 ...\n",
      "\n",
      "Average running time per epoch: 0.75 seconds\n",
      "Total running time: 14.26 seconds\n",
      "\n",
      "Test dataset metrics:\n",
      "Overall Accuracy = 79.9%, Matthews Corr Coef = 0.70\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      4755\n",
      "           1       0.90      0.88      0.89      3992\n",
      "           2       0.69      0.72      0.70      3588\n",
      "\n",
      "    accuracy                           0.80     12335\n",
      "   macro avg       0.80      0.80      0.80     12335\n",
      "weighted avg       0.80      0.80      0.80     12335\n",
      "\n",
      "\n",
      "\n",
      "Running combination of users  (0, 2, 3)\n",
      "\n",
      "\n",
      "-- New Fold --\n",
      "Train, test and validation arrays normalized to:\n",
      "[1.], [1.0004], [1.0004]\n",
      "Using Device:  cpu , dtype:  torch.float32\n",
      "\n",
      "Raw data shape:  (68779, 1, 32) \n",
      "Labels shape:  (68779,) \n",
      "Shape of test set: (13756, 1, 32) \n",
      "Shape of train set: (46769, 1, 32) \n",
      "Shape of validation set: (8254, 1, 32) \n",
      "Unique labels:  [0 1 2] \n",
      "Fraction of test labels:  [0.35, 0.32, 0.33] \n",
      "Fraction of validation labels:  [0.36, 0.33, 0.32] \n",
      "Fraction of train labels:  [0.35, 0.32, 0.33] \n",
      "dtype of inputs:  torch.float32\n",
      "\n",
      " Start of training model:\n",
      "\n",
      "End of epoch 1: loss_tr=0.587, loss_val=0.599, train=75.9%, val=75.2%\n",
      "End of epoch 3: loss_tr=0.544, loss_val=0.558, train=77.8%, val=77.3%\n",
      "End of epoch 5: loss_tr=0.572, loss_val=0.578, train=76.2%, val=76.0%\n",
      "End of epoch 7: loss_tr=0.520, loss_val=0.531, train=79.0%, val=78.1%\n",
      "End of epoch 9: loss_tr=0.493, loss_val=0.503, train=80.1%, val=79.4%\n",
      "End of epoch 11: loss_tr=0.580, loss_val=0.607, train=76.2%, val=75.5%\n",
      "End of epoch 13: loss_tr=0.513, loss_val=0.526, train=79.2%, val=78.5%\n",
      "End of epoch 15: loss_tr=0.488, loss_val=0.502, train=80.1%, val=79.3%\n",
      "End of epoch 17: loss_tr=0.514, loss_val=0.525, train=78.7%, val=78.3%\n",
      "End of epoch 19: loss_tr=0.478, loss_val=0.494, train=80.7%, val=80.0%\n",
      "\n",
      "Training Complete!\n",
      "Loading best weights for lowest validation loss=0.487 ...\n",
      "\n",
      "Average running time per epoch: 0.76 seconds\n",
      "Total running time: 14.50 seconds\n",
      "\n",
      "Test dataset metrics:\n",
      "Overall Accuracy = 80.6%, Matthews Corr Coef = 0.71\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82      4746\n",
      "           1       0.84      0.71      0.77      4469\n",
      "           2       0.80      0.86      0.83      4541\n",
      "\n",
      "    accuracy                           0.81     13756\n",
      "   macro avg       0.81      0.80      0.80     13756\n",
      "weighted avg       0.81      0.81      0.80     13756\n",
      "\n",
      "\n",
      "\n",
      "Running combination of users  (0, 2, 4)\n",
      "\n",
      "\n",
      "-- New Fold --\n",
      "Train, test and validation arrays normalized to:\n",
      "[1.], [1.0008], [1.0007]\n",
      "Using Device:  cpu , dtype:  torch.float32\n",
      "\n",
      "Raw data shape:  (64249, 1, 32) \n",
      "Labels shape:  (64249,) \n",
      "Shape of test set: (12850, 1, 32) \n",
      "Shape of train set: (43689, 1, 32) \n",
      "Shape of validation set: (7710, 1, 32) \n",
      "Unique labels:  [0 1 2] \n",
      "Fraction of test labels:  [0.37, 0.35, 0.28] \n",
      "Fraction of validation labels:  [0.38, 0.34, 0.28] \n",
      "Fraction of train labels:  [0.38, 0.35, 0.28] \n",
      "dtype of inputs:  torch.float32\n",
      "\n",
      " Start of training model:\n",
      "\n",
      "End of epoch 1: loss_tr=0.770, loss_val=0.780, train=64.6%, val=64.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 3: loss_tr=0.646, loss_val=0.661, train=70.5%, val=69.4%\n",
      "End of epoch 5: loss_tr=0.622, loss_val=0.639, train=71.9%, val=71.1%\n",
      "End of epoch 7: loss_tr=0.602, loss_val=0.621, train=73.2%, val=72.6%\n",
      "End of epoch 9: loss_tr=0.620, loss_val=0.637, train=72.0%, val=71.0%\n",
      "End of epoch 11: loss_tr=0.612, loss_val=0.633, train=72.4%, val=71.2%\n",
      "End of epoch 13: loss_tr=0.593, loss_val=0.614, train=73.1%, val=72.2%\n",
      "End of epoch 15: loss_tr=0.592, loss_val=0.607, train=73.4%, val=71.9%\n",
      "End of epoch 17: loss_tr=0.555, loss_val=0.572, train=75.2%, val=74.1%\n",
      "End of epoch 19: loss_tr=0.566, loss_val=0.584, train=74.3%, val=73.3%\n",
      "\n",
      "Training Complete!\n",
      "Loading best weights for lowest validation loss=0.572 ...\n",
      "\n",
      "Average running time per epoch: 0.72 seconds\n",
      "Total running time: 13.77 seconds\n",
      "\n",
      "Test dataset metrics:\n",
      "Overall Accuracy = 74.6%, Matthews Corr Coef = 0.62\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72      4729\n",
      "           1       0.82      0.80      0.81      4465\n",
      "           2       0.71      0.69      0.70      3656\n",
      "\n",
      "    accuracy                           0.75     12850\n",
      "   macro avg       0.75      0.74      0.74     12850\n",
      "weighted avg       0.75      0.75      0.75     12850\n",
      "\n",
      "\n",
      "\n",
      "Running combination of users  (0, 3, 4)\n",
      "\n",
      "\n",
      "-- New Fold --\n",
      "Train, test and validation arrays normalized to:\n",
      "[1.], [1.0012], [0.9989]\n",
      "Using Device:  cpu , dtype:  torch.float32\n",
      "\n",
      "Raw data shape:  (64373, 1, 32) \n",
      "Labels shape:  (64373,) \n",
      "Shape of test set: (12875, 1, 32) \n",
      "Shape of train set: (43773, 1, 32) \n",
      "Shape of validation set: (7725, 1, 32) \n",
      "Unique labels:  [0 1 2] \n",
      "Fraction of test labels:  [0.37, 0.35, 0.28] \n",
      "Fraction of validation labels:  [0.38, 0.34, 0.28] \n",
      "Fraction of train labels:  [0.37, 0.35, 0.28] \n",
      "dtype of inputs:  torch.float32\n",
      "\n",
      " Start of training model:\n",
      "\n",
      "End of epoch 1: loss_tr=0.640, loss_val=0.656, train=71.6%, val=71.5%\n",
      "End of epoch 3: loss_tr=0.633, loss_val=0.649, train=72.2%, val=71.6%\n",
      "End of epoch 5: loss_tr=0.596, loss_val=0.617, train=74.2%, val=73.5%\n",
      "End of epoch 7: loss_tr=0.592, loss_val=0.618, train=74.3%, val=73.4%\n",
      "End of epoch 9: loss_tr=0.567, loss_val=0.586, train=74.8%, val=74.7%\n",
      "End of epoch 11: loss_tr=0.557, loss_val=0.579, train=75.7%, val=74.9%\n",
      "End of epoch 13: loss_tr=0.553, loss_val=0.570, train=75.6%, val=75.1%\n",
      "End of epoch 15: loss_tr=0.560, loss_val=0.576, train=75.3%, val=75.1%\n",
      "End of epoch 17: loss_tr=0.535, loss_val=0.555, train=76.8%, val=75.9%\n",
      "End of epoch 19: loss_tr=0.607, loss_val=0.621, train=74.1%, val=73.5%\n",
      "\n",
      "Training Complete!\n",
      "Loading best weights for lowest validation loss=0.555 ...\n",
      "\n",
      "Average running time per epoch: 0.72 seconds\n",
      "Total running time: 13.71 seconds\n",
      "\n",
      "Test dataset metrics:\n",
      "Overall Accuracy = 76.8%, Matthews Corr Coef = 0.65\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      4723\n",
      "           1       0.79      0.87      0.83      4564\n",
      "           2       0.69      0.61      0.64      3588\n",
      "\n",
      "    accuracy                           0.77     12875\n",
      "   macro avg       0.76      0.76      0.76     12875\n",
      "weighted avg       0.76      0.77      0.76     12875\n",
      "\n",
      "\n",
      "\n",
      "Running combination of users  (1, 2, 3)\n",
      "\n",
      "\n",
      "-- New Fold --\n",
      "Train, test and validation arrays normalized to:\n",
      "[1.], [1.0004], [1.0006]\n",
      "Using Device:  cpu , dtype:  torch.float32\n",
      "\n",
      "Raw data shape:  (64490, 1, 32) \n",
      "Labels shape:  (64490,) \n",
      "Shape of test set: (12898, 1, 32) \n",
      "Shape of train set: (43853, 1, 32) \n",
      "Shape of validation set: (7739, 1, 32) \n",
      "Unique labels:  [0 1 2] \n",
      "Fraction of test labels:  [0.31, 0.34, 0.35] \n",
      "Fraction of validation labels:  [0.31, 0.35, 0.35] \n",
      "Fraction of train labels:  [0.31, 0.35, 0.35] \n",
      "dtype of inputs:  torch.float32\n",
      "\n",
      " Start of training model:\n",
      "\n",
      "End of epoch 1: loss_tr=0.658, loss_val=0.664, train=72.6%, val=72.3%\n",
      "End of epoch 3: loss_tr=0.596, loss_val=0.604, train=76.3%, val=75.6%\n",
      "End of epoch 5: loss_tr=0.550, loss_val=0.556, train=78.4%, val=77.9%\n",
      "End of epoch 7: loss_tr=0.563, loss_val=0.577, train=77.6%, val=76.1%\n",
      "End of epoch 9: loss_tr=0.546, loss_val=0.558, train=78.3%, val=77.6%\n",
      "End of epoch 11: loss_tr=0.522, loss_val=0.533, train=79.5%, val=78.8%\n",
      "End of epoch 13: loss_tr=0.507, loss_val=0.517, train=80.5%, val=80.0%\n",
      "End of epoch 15: loss_tr=0.510, loss_val=0.522, train=80.5%, val=79.7%\n",
      "End of epoch 17: loss_tr=0.513, loss_val=0.524, train=80.0%, val=79.2%\n",
      "End of epoch 19: loss_tr=0.496, loss_val=0.507, train=80.7%, val=79.8%\n",
      "\n",
      "Training Complete!\n",
      "Loading best weights for lowest validation loss=0.507 ...\n",
      "\n",
      "Average running time per epoch: 0.73 seconds\n",
      "Total running time: 13.89 seconds\n",
      "\n",
      "Test dataset metrics:\n",
      "Overall Accuracy = 80.7%, Matthews Corr Coef = 0.71\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.73      0.79      3941\n",
      "           1       0.82      0.85      0.83      4449\n",
      "           2       0.76      0.83      0.79      4508\n",
      "\n",
      "    accuracy                           0.81     12898\n",
      "   macro avg       0.81      0.80      0.81     12898\n",
      "weighted avg       0.81      0.81      0.81     12898\n",
      "\n",
      "\n",
      "\n",
      "Running combination of users  (1, 2, 4)\n",
      "\n",
      "\n",
      "-- New Fold --\n",
      "Train, test and validation arrays normalized to:\n",
      "[1.], [1.0024], [1.0015]\n",
      "Using Device:  cpu , dtype:  torch.float32\n",
      "\n",
      "Raw data shape:  (59960, 1, 32) \n",
      "Labels shape:  (59960,) \n",
      "Shape of test set: (11992, 1, 32) \n",
      "Shape of train set: (40772, 1, 32) \n",
      "Shape of validation set: (7196, 1, 32) \n",
      "Unique labels:  [0 1 2] \n",
      "Fraction of test labels:  [0.33, 0.37, 0.3] \n",
      "Fraction of validation labels:  [0.33, 0.37, 0.3] \n",
      "Fraction of train labels:  [0.33, 0.37, 0.3] \n",
      "dtype of inputs:  torch.float32\n",
      "\n",
      " Start of training model:\n",
      "\n",
      "End of epoch 1: loss_tr=0.568, loss_val=0.553, train=77.6%, val=78.1%\n",
      "End of epoch 3: loss_tr=0.484, loss_val=0.482, train=81.8%, val=82.0%\n",
      "End of epoch 5: loss_tr=0.441, loss_val=0.435, train=83.5%, val=83.7%\n",
      "End of epoch 7: loss_tr=0.473, loss_val=0.463, train=81.9%, val=82.6%\n",
      "End of epoch 9: loss_tr=0.446, loss_val=0.441, train=83.2%, val=83.2%\n",
      "End of epoch 11: loss_tr=0.459, loss_val=0.450, train=83.0%, val=83.7%\n",
      "End of epoch 13: loss_tr=0.431, loss_val=0.426, train=83.8%, val=84.1%\n",
      "End of epoch 15: loss_tr=0.420, loss_val=0.415, train=84.0%, val=84.5%\n",
      "End of epoch 17: loss_tr=0.402, loss_val=0.402, train=84.8%, val=84.7%\n",
      "End of epoch 19: loss_tr=0.532, loss_val=0.527, train=78.1%, val=78.1%\n",
      "\n",
      "Training Complete!\n",
      "Loading best weights for lowest validation loss=0.402 ...\n",
      "\n",
      "Average running time per epoch: 0.69 seconds\n",
      "Total running time: 13.06 seconds\n",
      "\n",
      "Test dataset metrics:\n",
      "Overall Accuracy = 84.4%, Matthews Corr Coef = 0.77\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.82      0.86      3915\n",
      "           1       0.86      0.85      0.85      4491\n",
      "           2       0.79      0.86      0.82      3586\n",
      "\n",
      "    accuracy                           0.84     11992\n",
      "   macro avg       0.84      0.84      0.84     11992\n",
      "weighted avg       0.85      0.84      0.84     11992\n",
      "\n",
      "\n",
      "\n",
      "Running combination of users  (1, 3, 4)\n",
      "\n",
      "\n",
      "-- New Fold --\n",
      "Train, test and validation arrays normalized to:\n",
      "[1.], [0.9996], [0.9988]\n",
      "Using Device:  cpu , dtype:  torch.float32\n",
      "\n",
      "Raw data shape:  (60084, 1, 32) \n",
      "Labels shape:  (60084,) \n",
      "Shape of test set: (12017, 1, 32) \n",
      "Shape of train set: (40856, 1, 32) \n",
      "Shape of validation set: (7211, 1, 32) \n",
      "Unique labels:  [0 1 2] \n",
      "Fraction of test labels:  [0.33, 0.37, 0.3] \n",
      "Fraction of validation labels:  [0.33, 0.37, 0.3] \n",
      "Fraction of train labels:  [0.33, 0.37, 0.3] \n",
      "dtype of inputs:  torch.float32\n",
      "\n",
      " Start of training model:\n",
      "\n",
      "End of epoch 1: loss_tr=0.700, loss_val=0.704, train=71.1%, val=71.1%\n",
      "End of epoch 3: loss_tr=0.611, loss_val=0.610, train=74.6%, val=74.5%\n",
      "End of epoch 5: loss_tr=0.570, loss_val=0.571, train=76.7%, val=76.6%\n",
      "End of epoch 7: loss_tr=0.584, loss_val=0.588, train=75.7%, val=75.8%\n",
      "End of epoch 9: loss_tr=0.555, loss_val=0.562, train=76.8%, val=76.4%\n",
      "End of epoch 11: loss_tr=0.584, loss_val=0.584, train=75.9%, val=75.8%\n",
      "End of epoch 13: loss_tr=0.549, loss_val=0.556, train=76.7%, val=76.1%\n",
      "End of epoch 15: loss_tr=0.553, loss_val=0.556, train=76.8%, val=76.5%\n",
      "End of epoch 17: loss_tr=0.549, loss_val=0.553, train=76.8%, val=76.4%\n",
      "End of epoch 19: loss_tr=0.643, loss_val=0.650, train=71.6%, val=71.9%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Complete!\n",
      "Loading best weights for lowest validation loss=0.550 ...\n",
      "\n",
      "Average running time per epoch: 0.67 seconds\n",
      "Total running time: 12.74 seconds\n",
      "\n",
      "Test dataset metrics:\n",
      "Overall Accuracy = 76.8%, Matthews Corr Coef = 0.65\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.74      0.79      3910\n",
      "           1       0.71      0.81      0.75      4478\n",
      "           2       0.78      0.75      0.76      3629\n",
      "\n",
      "    accuracy                           0.77     12017\n",
      "   macro avg       0.78      0.77      0.77     12017\n",
      "weighted avg       0.77      0.77      0.77     12017\n",
      "\n",
      "\n",
      "\n",
      "Running combination of users  (2, 3, 4)\n",
      "\n",
      "\n",
      "-- New Fold --\n",
      "Train, test and validation arrays normalized to:\n",
      "[1.], [1.0005], [0.999]\n",
      "Using Device:  cpu , dtype:  torch.float32\n",
      "\n",
      "Raw data shape:  (62660, 1, 32) \n",
      "Labels shape:  (62660,) \n",
      "Shape of test set: (12532, 1, 32) \n",
      "Shape of train set: (42608, 1, 32) \n",
      "Shape of validation set: (7520, 1, 32) \n",
      "Unique labels:  [0 1 2] \n",
      "Fraction of test labels:  [0.35, 0.36, 0.29] \n",
      "Fraction of validation labels:  [0.36, 0.36, 0.29] \n",
      "Fraction of train labels:  [0.36, 0.36, 0.29] \n",
      "dtype of inputs:  torch.float32\n",
      "\n",
      " Start of training model:\n",
      "\n",
      "End of epoch 1: loss_tr=0.590, loss_val=0.598, train=75.9%, val=76.0%\n",
      "End of epoch 3: loss_tr=0.563, loss_val=0.564, train=77.1%, val=76.9%\n",
      "End of epoch 5: loss_tr=0.538, loss_val=0.540, train=77.9%, val=77.8%\n",
      "End of epoch 7: loss_tr=0.570, loss_val=0.566, train=75.9%, val=75.9%\n",
      "End of epoch 9: loss_tr=0.534, loss_val=0.535, train=78.3%, val=78.1%\n",
      "End of epoch 11: loss_tr=0.508, loss_val=0.509, train=79.4%, val=78.9%\n",
      "End of epoch 13: loss_tr=0.610, loss_val=0.611, train=74.2%, val=73.7%\n",
      "End of epoch 15: loss_tr=0.547, loss_val=0.542, train=77.6%, val=77.3%\n",
      "End of epoch 17: loss_tr=0.511, loss_val=0.505, train=79.1%, val=79.4%\n",
      "End of epoch 19: loss_tr=0.499, loss_val=0.500, train=79.7%, val=79.3%\n",
      "\n",
      "Training Complete!\n",
      "Loading best weights for lowest validation loss=0.499 ...\n",
      "\n",
      "Average running time per epoch: 0.70 seconds\n",
      "Total running time: 13.29 seconds\n",
      "\n",
      "Test dataset metrics:\n",
      "Overall Accuracy = 80.2%, Matthews Corr Coef = 0.70\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.80      0.84      4415\n",
      "           1       0.74      0.85      0.79      4519\n",
      "           2       0.79      0.74      0.77      3598\n",
      "\n",
      "    accuracy                           0.80     12532\n",
      "   macro avg       0.81      0.80      0.80     12532\n",
      "weighted avg       0.81      0.80      0.80     12532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from peratouch.config import path_analysis_results\n",
    "import itertools\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "number_users = range(3, 4)\n",
    "for n_users in number_users:     # Number of possible users: 2, 3, 4, 5\n",
    "\n",
    "    user_combinations = itertools.combinations(range(5), n_users)      # From 5 users choose n_users\n",
    "\n",
    "    for users in user_combinations:\n",
    "        print(\"\\n\\nRunning combination of users \", users)\n",
    "\n",
    "        Xraw, yraw = load_data(path_five_users_main)\n",
    "\n",
    "        # Choose one given combination of users\n",
    "        Xraw = np.concatenate([Xraw[yraw==u] for u in users])\n",
    "        yraw = np.concatenate([yraw[yraw==u] for u in users])\n",
    "\n",
    "        # Change labels to be fit increasing range ie. 0, 1, 2, ....\n",
    "        for i, u in enumerate(users):\n",
    "            yraw[yraw==u] = i\n",
    "\n",
    "        # Shuffle data to destroy ordering of users\n",
    "        Xraw, yraw = sklearn.utils.shuffle(Xraw, yraw, random_state=42)\n",
    "\n",
    "        # Run same routine for users selected\n",
    "        results_dict[str(users)] = run_n_users(Xraw, yraw)\n",
    "\n",
    "        # Store results at each run\n",
    "        np.savez(str(path_analysis_results / \"number_users.npz\"), **results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a823f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 2)  :  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.83      4703\n",
      "           1       0.87      0.85      0.86      4015\n",
      "           2       0.85      0.72      0.78      4498\n",
      "\n",
      "    accuracy                           0.83     13216\n",
      "   macro avg       0.83      0.83      0.83     13216\n",
      "weighted avg       0.83      0.83      0.82     13216\n",
      "\n",
      "(0, 1, 3)  :  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      4722\n",
      "           1       0.84      0.76      0.80      3963\n",
      "           2       0.79      0.80      0.80      4556\n",
      "\n",
      "    accuracy                           0.83     13241\n",
      "   macro avg       0.83      0.82      0.82     13241\n",
      "weighted avg       0.83      0.83      0.83     13241\n",
      "\n",
      "(0, 1, 4)  :  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      4755\n",
      "           1       0.90      0.88      0.89      3992\n",
      "           2       0.69      0.72      0.70      3588\n",
      "\n",
      "    accuracy                           0.80     12335\n",
      "   macro avg       0.80      0.80      0.80     12335\n",
      "weighted avg       0.80      0.80      0.80     12335\n",
      "\n",
      "(0, 2, 3)  :  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82      4746\n",
      "           1       0.84      0.71      0.77      4469\n",
      "           2       0.80      0.86      0.83      4541\n",
      "\n",
      "    accuracy                           0.81     13756\n",
      "   macro avg       0.81      0.80      0.80     13756\n",
      "weighted avg       0.81      0.81      0.80     13756\n",
      "\n",
      "(0, 2, 4)  :  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72      4729\n",
      "           1       0.82      0.80      0.81      4465\n",
      "           2       0.71      0.69      0.70      3656\n",
      "\n",
      "    accuracy                           0.75     12850\n",
      "   macro avg       0.75      0.74      0.74     12850\n",
      "weighted avg       0.75      0.75      0.75     12850\n",
      "\n",
      "(0, 3, 4)  :  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      4723\n",
      "           1       0.79      0.87      0.83      4564\n",
      "           2       0.69      0.61      0.64      3588\n",
      "\n",
      "    accuracy                           0.77     12875\n",
      "   macro avg       0.76      0.76      0.76     12875\n",
      "weighted avg       0.76      0.77      0.76     12875\n",
      "\n",
      "(1, 2, 3)  :  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.73      0.79      3941\n",
      "           1       0.82      0.85      0.83      4449\n",
      "           2       0.76      0.83      0.79      4508\n",
      "\n",
      "    accuracy                           0.81     12898\n",
      "   macro avg       0.81      0.80      0.81     12898\n",
      "weighted avg       0.81      0.81      0.81     12898\n",
      "\n",
      "(1, 2, 4)  :  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.82      0.86      3915\n",
      "           1       0.86      0.85      0.85      4491\n",
      "           2       0.79      0.86      0.82      3586\n",
      "\n",
      "    accuracy                           0.84     11992\n",
      "   macro avg       0.84      0.84      0.84     11992\n",
      "weighted avg       0.85      0.84      0.84     11992\n",
      "\n",
      "(1, 3, 4)  :  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.74      0.79      3910\n",
      "           1       0.71      0.81      0.75      4478\n",
      "           2       0.78      0.75      0.76      3629\n",
      "\n",
      "    accuracy                           0.77     12017\n",
      "   macro avg       0.78      0.77      0.77     12017\n",
      "weighted avg       0.77      0.77      0.77     12017\n",
      "\n",
      "(2, 3, 4)  :  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.80      0.84      4415\n",
      "           1       0.74      0.85      0.79      4519\n",
      "           2       0.79      0.74      0.77      3598\n",
      "\n",
      "    accuracy                           0.80     12532\n",
      "   macro avg       0.81      0.80      0.80     12532\n",
      "weighted avg       0.81      0.80      0.80     12532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stored_results = np.load(str(path_analysis_results / \"number_users.npz\"))\n",
    "\n",
    "dict_plot = {}\n",
    "# Initialize lists for numner of users\n",
    "for n in number_users:\n",
    "    dict_plot[n] = []\n",
    "\n",
    "for key in stored_results:\n",
    "    print(key, \" : \", len(results_dict[key]))\n",
    "    print(sklearn.metrics.classification_report(*results_dict[key]))\n",
    "    actual, pred = stored_results[key]\n",
    "    dict_plot[len(eval(key))].append(np.mean(actual==pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bef4986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  :  [0.8261198547215496, 0.8274299524205121, 0.7991082286177543, 0.8058301831927887, 0.746147859922179, 0.768, 0.8065591564583656, 0.8437291527685123, 0.7680785553798785, 0.802026811362911]\n",
      "3 :  0.799302975484445  +/-  0.028925728820840466\n"
     ]
    }
   ],
   "source": [
    "for key in dict_plot:\n",
    "    run_data = dict_plot[key]\n",
    "    print(key, \" : \", run_data)\n",
    "    print(key, \": \", np.mean(run_data), \" +/- \", np.std(run_data))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
